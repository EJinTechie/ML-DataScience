{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "from statistics import linear_regression\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "X,y = mglearn.datasets.make_wave(n_samples=40)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)\n",
    "\n",
    "reg=KNeighborsRegressor(n_neighbors=3)\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 세트 예측 : \\n\", reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트 세트 R^2 : \", reg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3,figsize=(15,4))\n",
    "line=np.linspace(-3,3,1000).reshape(-1,1)\n",
    "for n_neighbors, ax in zip([1,3,9],axes):\n",
    "    reg=KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train,y_train)\n",
    "    ax.plot(line,reg.predict(line))\n",
    "    ax.plot(X_train,y_train,'^',c=mglearn.cm2(0),markersize=8)\n",
    "    ax.plot(X_test,y_test,'v',c=mglearn.cm2(1),markersize=8)\n",
    "    ax.set_title(\n",
    "        \"{} 이웃의 훈련 스코어: {:.2f} 테스트 스코어: {:.2f}\".format(n_neighbors,reg.score(X_train,y_train), reg.score(X_test,y_test))\n",
    "    )\n",
    "    ax.set_xlabel(\"특성\")\n",
    "    ax.set_ylabel(\"타겟\")\n",
    "    axes[0].legend([\"모델 예측\",\"훈련 데이터/타깃\",\"테스트 데이터/타깃\"],loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X,y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n",
    "lr=LinearRegression().fit(X_train,y_train)\n",
    "#weight\n",
    "print(lr.coef_)\n",
    "#bias\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train set score : \", lr.score(X_train,y_train))\n",
    "print(\"test set score : \", lr.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "보스턴 집값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)\n",
    "lr=LinearRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows that the model overfit by LR\n",
    "print(f\"train score : {lr.score(X_train,y_train):.2f}\")\n",
    "print(f\"test score : {lr.score(X_test,y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge is less flexible model than LR so better results\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(X_train,y_train)\n",
    "print(f\"train score : {ridge.score(X_train,y_train):.2f}\")\n",
    "print(f\"test score : {ridge.score(X_test,y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train,y_train)\n",
    "print(f\"train score : {ridge10.score(X_train, y_train):.2f}\")\n",
    "print(f\"test score : {ridge10.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha 값 줄이면 계수에 대한 제약이 그만큼 풀리니 선형회귀와 비슷\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train,y_train)\n",
    "print(f\"train score : {ridge01.score(X_train, y_train):.2f}\")\n",
    "print(f\"test score : {ridge01.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ridge10.coef_,'^',label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge.coef_,'^',label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge01.coef_,'^',label=\"Ridge alpha=0.1\")\n",
    "\n",
    "plt.plot(lr.coef_,'o',label=\"LinearRegression\")\n",
    "plt.xlabel(\"Number of Weights\")\n",
    "plt.ylabel(\"Size of Weights\")\n",
    "xlims=plt.xlim()\n",
    "plt.hlines(0,xlims[0],xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-25,25)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_ridge_n_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso 로 인해 어떤 계수는 0이 되기도 함\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso =Lasso().fit(X_train,y_train)\n",
    "print(f\"train set score : {lasso.score(X_train,y_train):.2f}\")\n",
    "print(f\"test set score : {lasso.score(X_test,y_test):.2f}\")\n",
    "print(f\"number of feature used : {np.sum(lasso.coef_ !=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso001 = Lasso(alpha=0.01,max_iter=100000).fit(X_train,y_train)\n",
    "print(f\"train set score : {lasso001.score(X_train,y_train):.2f}\")\n",
    "print(f\"test set score : {lasso001.score(X_test,y_test):.2f}\")\n",
    "print(f\"number of feature used : {np.sum(lasso001.coef_ !=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha 값을 너무 낮추면 규제의 효과가 없어져 과대적합이 되므로 LR 과 결과 비슷해짐\n",
    "lasso00001 = Lasso(alpha=0.0001,max_iter=100000).fit(X_train,y_train)\n",
    "print(f\"train set score : {lasso00001.score(X_train,y_train):.2f}\")\n",
    "print(f\"test set score : {lasso00001.score(X_test,y_test):.2f}\")\n",
    "print(f\"number of feature used : {np.sum(lasso00001.coef_ !=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
